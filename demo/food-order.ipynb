{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959b8348-fb4b-4ee0-b96b-063baf998ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in ./.env312/lib/python3.12/site-packages (2.8.2)\n",
      "Requirement already satisfied: openai in ./.env312/lib/python3.12/site-packages (1.43.0)\n",
      "Requirement already satisfied: langchain in ./.env312/lib/python3.12/site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain-community in ./.env312/lib/python3.12/site-packages (0.2.15)\n",
      "Requirement already satisfied: langgraph in ./.env312/lib/python3.12/site-packages (0.2.15)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-anthropic in ./.env312/lib/python3.12/site-packages (0.1.23)\n",
      "Requirement already satisfied: tavily-python in ./.env312/lib/python3.12/site-packages (0.4.0)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.env312/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-openai in ./.env312/lib/python3.12/site-packages (0.1.23)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.env312/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.env312/lib/python3.12/site-packages (from pydantic) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.env312/lib/python3.12/site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.env312/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.env312/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.env312/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.env312/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./.env312/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.env312/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.env312/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.env312/lib/python3.12/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.env312/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in ./.env312/lib/python3.12/site-packages (from langchain) (0.2.37)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.env312/lib/python3.12/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.env312/lib/python3.12/site-packages (from langchain) (0.1.108)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./.env312/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.env312/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.env312/lib/python3.12/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.env312/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in ./.env312/lib/python3.12/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: anthropic<1,>=0.30.0 in ./.env312/lib/python3.12/site-packages (from langchain-anthropic) (0.34.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./.env312/lib/python3.12/site-packages (from langchain-anthropic) (0.7.1)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in ./.env312/lib/python3.12/site-packages (from tavily-python) (0.7.0)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.env312/lib/python3.12/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.env312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.6)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in ./.env312/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.20.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.env312/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.env312/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.env312/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.env312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.env312/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.env312/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.env312/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.env312/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.env312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.env312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.env312/lib/python3.12/site-packages (from tiktoken>=0.5.1->tavily-python) (2024.7.24)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.env312/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.env312/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (0.24.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.env312/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: filelock in ./.env312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.env312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (2024.6.1)\n",
      "Downloading langgraph-0.2.16-py3-none-any.whl (91 kB)\n",
      "Installing collected packages: langgraph\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.2.15\n",
      "    Uninstalling langgraph-0.2.15:\n",
      "      Successfully uninstalled langgraph-0.2.15\n",
      "Successfully installed langgraph-0.2.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pydantic openai langchain langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77d0dfd8-a4e7-49a2-89d1-14a0c98726a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c46b4d7e-43e0-447d-8215-ce5f9158a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "assert \"ANTHROPIC_API_KEY\" in os.environ , \"get your antrhopic api key after registring and set as env variable\"\n",
    "assert \"OPENAI_API_KEY\" in os.environ\n",
    "assert \"LANGCHAIN_API_KEY\" in os.environ,  \"get your langsmith api key after registring and set as env variable\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5ec1b3-12e8-429f-a3e9-88bd5230a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a8c9c9-d488-47f9-a499-115bf8bc2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"nasscom\"\n",
    "# LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786fe4ca-55eb-4d14-b594-46e290a3a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SIZES = [\"small\", \"medium\", \"large\"]\n",
    "VALID_TOPPINGS = [\"capsicum\", \"tomatoes\", \"olives\", \"mushrooms\", \"onions\", \"jalapenos\", \"pineapple\", \"pepperoni\"]\n",
    "VALID_SIDES = [\"garlic bread\", \"choco lava cake\", \"chicken taco\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bdc8cfb4-1e70-42bd-9de2-1c1692d14806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.tools import tool\n",
    "\n",
    "order_count = 0\n",
    "order_status_db={}\n",
    "\n",
    "\n",
    "\n",
    "def pizza_order(pizza_size: str, pizza_toppings: List[str], side_items: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Places an order for a pizza with the specified size, toppings, and side items. Must be invoked once the order details are confirmed by the user\n",
    "\n",
    "    Args:\n",
    "        pizza_size (str): The size of the pizza to order (e.g., 'small', 'medium', 'large').\n",
    "        pizza_toppings (List[str]): A list of toppings to add to the pizza.\n",
    "        side_items (List[str]): A list of side items to include with the order.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating whether the order was placed successfully, or an error message if there were invalid inputs.\n",
    "\n",
    "    Example:\n",
    "        >>> pizza_order('large', ['pepperoni', 'mushrooms'], ['garlic bread', 'soda'])\n",
    "        \"Your order has been placed successfully! Here are the details:\\n{'pizza_size': 'large', 'pizza_toppings': ['pepperoni', 'mushrooms'], 'side_items': ['garlic bread', 'soda']}\"\n",
    "    \"\"\"\n",
    "\n",
    "    global order_count\n",
    "    \n",
    "    # Basic validation and order processing logic\n",
    "    if pizza_size not in VALID_SIZES:\n",
    "        return f\"Error: Invalid pizza size '{pizza_size}'. Please choose from {VALID_SIZES}.\"\n",
    "    \n",
    "    invalid_toppings = [topping for topping in pizza_toppings if topping not in VALID_TOPPINGS]\n",
    "    if invalid_toppings:\n",
    "        return f\"Error: Invalid toppings {invalid_toppings}. Please choose from {VALID_TOPPINGS}.\"\n",
    "    \n",
    "    invalid_sides = [side for side in side_items if side not in VALID_SIDES]\n",
    "    if invalid_sides:\n",
    "        return f\"Error: Invalid side items {invalid_sides}. Please choose from {VALID_SIDES}.\"\n",
    "    order_count+=1\n",
    "    \n",
    "    order_details = {\n",
    "        \"pizza_size\": pizza_size,\n",
    "        \"pizza_toppings\": pizza_toppings,\n",
    "        \"side_items\": side_items,\n",
    "        \"order_id\": order_count,\n",
    "    }\n",
    "    order_status_db[order_count] = \"pending\"\n",
    "    return f\"Your order has been placed successfully! Your order id is: {order_count}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd442a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def order_status(order_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves the status of a pizza order based on the order ID.\n",
    "\n",
    "    Args:\n",
    "        order_id (int): The ID of the order to check the status of.\n",
    "\n",
    "    Returns:\n",
    "        str: A message indicating the status of the order, or an error message if the order ID is invalid.\n",
    "\n",
    "    Example:\n",
    "        >>> order_status(1)\n",
    "        \"Order 1 is pending.\"\n",
    "    \"\"\"\n",
    "\n",
    "    if order_id not in order_status_db:\n",
    "        return f\"Error: Order ID {order_id} not found.\"\n",
    "    \n",
    "    return f\"Order {order_id} is {order_status_db[order_id]}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f882f45-2538-4e27-8e8a-fb0e3067cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza_doc=f\"\"\"- The pizzas are freshly baked using wheat base and will be served within 10 minutes of ordering.\n",
    "- Pizza is available in one of the three sizes:-  {\", \".join(VALID_SIZES)}\n",
    "- Any number of toppings can be added to a pizza\n",
    "- Pizza toppings can be one of these:- {\", \".join(VALID_TOPPINGS)}\n",
    "- The large pizza should be enough for about 4 people\n",
    "- The medium pizza should be enough for about 2 people\n",
    "- The small pizza should be enough for about 1 person\n",
    "- Allergen Information:\n",
    "    - The choco lava cake contains peanut oil\n",
    "    - The chick taco contains soya\n",
    "    - all products include milk based ingredients.\n",
    "- We do not have an option for extra cheese on the pizza\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5a0a96d-cb5a-4cdb-a915-6eb7b62b679a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- The pizzas are freshly baked using wheat base and will be served within 10 minutes of ordering.\n",
       "- Pizza is available in one of the three sizes:-  small, medium, large\n",
       "- Any number of toppings can be added to a pizza\n",
       "- Pizza toppings can be one of these:- capsicum, tomatoes, olives, mushrooms, onions, jalapenos, pineapple, pepperoni\n",
       "- The large pizza should be enough for about 4 people\n",
       "- The medium pizza should be enough for about 2 people\n",
       "- The small pizza should be enough for about 1 person\n",
       "- Allergen Information:\n",
       "    - The choco lava cake contains peanut oil\n",
       "    - The chick taco contains soya\n",
       "    - all products include milk based ingredients.\n",
       "- We do not have an option for extra cheese on the pizza\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(pizza_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e26db36-9c58-4b60-aaf4-949046782974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a friendly but rule bound pizza ordering assisstant. You should respond to the user query based on the following information:-\\n- The pizzas are freshly baked using wheat base and will be served within 10 minutes of ordering.\\n- Pizza is available in one of the three sizes:-  small, medium, large\\n- Any number of toppings can be added to a pizza\\n- Pizza toppings can be one of these:- capsicum, tomatoes, olives, mushrooms, onions, jalapenos, pineapple, pepperoni\\n- The large pizza should be enough for about 4 people\\n- The medium pizza should be enough for about 2 people\\n- The small pizza should be enough for about 1 person\\n- Allergen Information:\\n    - The choco lava cake contains peanut oil\\n    - The chick taco contains soya\\n    - all products include milk based ingredients.\\n- We do not have an option for extra cheese on the pizza\\n\\nIn case the user query cannot be responded to based on the above information, Respond by literally saying \"I am not sure about this\"\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_response_prompt=f\"\"\"You are a friendly but rule bound pizza ordering assisstant. You should respond to the user query based on the following information:-\n",
    "{pizza_doc}\n",
    "In case the user query cannot be responded to based on the above information, Respond by literally saying \"I am not sure about this\"\n",
    "\"\"\"\n",
    "question_response_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "23f756f0-ff3b-41a1-9be4-7765f6048876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "# llm= ChatAnthropic(model=\"claude-3-5-sonnet-20240620\",temperature=0)\n",
    "# llm=ChatAnthropic(model=\"claude-3-haiku-20240307\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "94a97c66-3b51-47b1-8181-95486334b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import AnyMessage,add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ea9ea6c-d4ee-4c2e-a54d-09e5a53f5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    size:str\n",
    "    toppings:list[str]\n",
    "    sides:list[str]\n",
    "    confirmed:bool\n",
    "    next:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c17c04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a supervisor tasked with picking the right worker to act upon user queries. You may allocate the user query to one the following workers:-\n",
      "order_taker: This worker keep track of user's pizza order, specifically tracks the size of pizza,list of toppings and side items. Choose this worker if the user query is related to updating the order\n",
      "helper: Answers general user queries about pizza and order. Choose this worker only if of none of the other workers are suitable to respond\n",
      "order_status: This worker keeps track of the status of the order. Choose this worker if the user query is related to the status of the order\n",
      "Always respond concisely ONLY with the name of the worker most suitable to respond to the most recent user query\n"
     ]
    }
   ],
   "source": [
    "helper_nodes={\n",
    "    \"order_taker\": \"This worker keep track of user's pizza order, specifically tracks the size of pizza,list of toppings and side items. Choose this worker if the user query is related to updating the order\",\n",
    "    \"helper\":\"Answers general user queries about pizza and order. Choose this worker only if of none of the other workers are suitable to respond\",\n",
    "    \"order_status\":\"This worker keeps track of the status of the order. Choose this worker if the user query is related to the status of the order\",\n",
    "}\n",
    "worker_descriptions = \"\\n\".join([f\"{name}: {description}\" for name, description in helper_nodes.items()])\n",
    "router_agent_prompt=\"You are a supervisor tasked with picking the right worker to act upon user queries. You may allocate the user query to one the following workers:-\\n\" \\\n",
    "+ worker_descriptions \\\n",
    "+\"\\nAlways respond concisely ONLY with the name of the worker most suitable to respond to the most recent user query\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(router_agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a49b576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal,Optional\n",
    "# options = [\"FINISH\"] + list(helper_nodes.keys())\n",
    "options = list(helper_nodes.keys())\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[*options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b390df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class orderTakeResponse(BaseModel):\n",
    "    size:Optional[Literal[*VALID_SIZES]]\n",
    "    toppings:List[Literal[*VALID_TOPPINGS]]\n",
    "    sides:List[Literal[*VALID_SIDES]]\n",
    "    confirmed:bool\n",
    "    response:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c04c9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e3cbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", router_agent_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        \n",
    "    ]\n",
    ").partial(options=str(options))\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    supervisor_chain = (\n",
    "        router_prompt\n",
    "        | llm.with_structured_output(routeResponse)\n",
    "    )\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d340afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent(state)\n",
    "    \n",
    "    # if hasattr(result,\"tool_calls\") and result.tool_calls:\n",
    "    #     print(\"Requested tool call\", result.tool_calls)\n",
    "    # else:\n",
    "    #     print(\"No tool call requested\")\n",
    "    if hasattr(result,\"content\"):\n",
    "        return {\"messages\": [AIMessage(content=result.content, name=name)]}\n",
    "    elif hasattr(result,\"response\"):\n",
    "        return {\"messages\": [AIMessage(content=result.response, name=name)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "139625a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "752a12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_taker_node_factory(state,agent,name):\n",
    "    result = agent(state)\n",
    "    response={}\n",
    "    response[\"messages\"]=[HumanMessage(content=result.response, name=name)]\n",
    "    response[\"size\"]=result.size\n",
    "    response[\"toppings\"]=result.toppings\n",
    "    response[\"sides\"]=result.sides\n",
    "    response[\"confirmed\"]=result.confirmed\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "585457fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", question_response_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "def helper_agent(state):\n",
    "    helper_chain = (\n",
    "        helper_prompt\n",
    "        | llm\n",
    "    )\n",
    "    return helper_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "252d3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_taker_prompt=\"You are a professional, concise server responsible for taking the user's pizza order. Only following information is relevant about the order:-\\n\" + \\\n",
    "f\"- Size of the pizza, it should be one of the these:- {', '.join(VALID_SIZES)} \\n\" + \\\n",
    "f\"- Toppings to be added to the pizza, User may only add on or some of these:- {', '.join(VALID_TOPPINGS)}\\n\" + \\\n",
    "f\"- Side items to be added to the order, User may only add on or some of these:- {', '.join(VALID_SIDES)}\\n\" + \\\n",
    "\"Acknowledge user's request by making an acceptance statement but in case the user request is confusing, feel free to ask clarifying question. In case user has not provided all information regarding a order, ask for it one at a time. Ensure that you ask the user If he wants to add any additional toppings or side items unless that have already confirmed that they don't. Maintain the continuity of the conversation and do *not* jumping across topics. Be patient and only ask one question in a single response.\" +\\\n",
    "\"In case the user has asked any clarifying questions, respond to them on the basis of following information only:-\\n\" + \\\n",
    "f\"{pizza_doc}\" +\\\n",
    "\"In case the user query cannot be responded to based on the above information, Respond by literally saying 'I am not sure about this'\" +\\\n",
    "\"*Respond in the form of a json object with following schema*:-\\n\" + \\\n",
    "\"\"\"{{\n",
    "    \"pizza_size\": str, // The size of the pizza to order\n",
    "    \"pizza_toppings\": List[str], // A list of toppings to add to the pizza\n",
    "    \"side_items\": List[str] // A list of side items to include with the order\n",
    "    \"response\": str //A response to the user based on the last update, It may be clarifying question about the user's request, a confirmation message or a probing question about the orde. Be concise and to the point\n",
    "    \"confirmed:bool // A boolean value indicating whether all information is available and confirmed from the user. One you set this to true, the order will be placed and cannot be updated further\n",
    "\n",
    "}}\"\"\" +\\\n",
    "\"Remember to *always* respond to the user query in the form of a json object with the above schema only. \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "97c52f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", order_taker_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "def order_taker_agent(state):\n",
    "    order_take_chain = (\n",
    "        order_prompt\n",
    "        | llm.bind_tools([pizza_order]).with_structured_output(orderTakeResponse) #add tool call here\n",
    "    )\n",
    "    return order_take_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d748acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unimplemented_agent_node(state,name):\n",
    "    return {\"messages\": [HumanMessage(content=\"This will be replaced by real message\",name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "96314296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order_node_factory(state,name):\n",
    "    response=pizza_order(state[\"size\"],state[\"toppings\"],state[\"sides\"])\n",
    "    return {\"messages\": [AIMessage(content=response,name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8998dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "import functools\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "helper_node=functools.partial(agent_node, agent=helper_agent, name=\"helper\")\n",
    "workflow.add_node(\"helper\", helper_node)\n",
    "order_taker_node=functools.partial(order_taker_node_factory,agent=order_taker_agent, name=\"order_taker\")\n",
    "workflow.add_node(\"order_taker\", order_taker_node)\n",
    "\n",
    "place_order_node=functools.partial(place_order_node_factory, name=\"order_place\")\n",
    "workflow.add_node(\"order_place\", place_order_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ae58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ddc5963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "tools=[order_status]\n",
    "model=llm.bind_tools(tools)\n",
    "order_status_agent = create_react_agent(model, tools)\n",
    "order_status_node=functools.partial(invoke_agent_node, agent=order_status_agent, name=\"order_status\")\n",
    "workflow.add_node(\"order_status\", order_status_node)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "workflow.add_node(\"tools\", tool_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e11d4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_place_condition(state):\n",
    "    if state[\"confirmed\"]:\n",
    "        return \"order_place\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3449c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from superviser to routed nodes    \n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"],{\"order_taker\":\"order_taker\",\"helper\":\"helper\",\"order_status\":\"order_status\"})\n",
    "workflow.add_conditional_edges(\"order_taker\",order_place_condition,{\"order_place\":\"order_place\",END:END})\n",
    "workflow.add_conditional_edges(\"order_status\",tools_condition,{\"tools\":\"tools\",END:END})\n",
    "workflow.add_edge(\"order_place\", END)\n",
    "workflow.add_edge(\"helper\", END)\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "18787aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fc97ddf3-e911-4dc3-8449-8eb602c3d8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1e7d0635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'pending', 2: 'pending', 3: 'pending', 4: 'pending'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_status_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3ba17a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_taker'}}\n",
      "----\n",
      "{'order_taker': {'messages': [HumanMessage(content='Great choice! What toppings would you like on your large pizza? You can choose from capsicum, tomatoes, olives, mushrooms, onions, jalapenos, pineapple, and pepperoni.', name='order_taker', id='dd4447a8-1bc2-44ac-bb1d-712fbb7cc7e3')], 'size': 'large', 'toppings': [], 'sides': [], 'confirmed': False}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream({\n",
    "        \"messages\": [            \n",
    "            HumanMessage(content=\"I want to order a large pizza\"),\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 3},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6864788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'pending', 2: 'pending', 3: 'pending', 4: 'pending'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_status_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a6c9ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_taker'}}\n",
      "----\n",
      "{'order_taker': {'messages': [HumanMessage(content='Thank you for your order! Your large pizza with onion, capsicum, and tomato toppings, along with a garlic bread, will be served within 10 minutes.', name='order_taker', id='720662be-7925-4471-9583-82ed031cfde4')], 'size': 'large', 'toppings': ['onions', 'capsicum', 'tomatoes'], 'sides': ['garlic bread'], 'confirmed': True}}\n",
      "----\n",
      "{'order_place': {'messages': [AIMessage(content='Your order has been placed successfully! Your order id is: 5', name='order_place')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to order a medium pizza with onion, capsicum and tomato toppings\"),\n",
    "        AIMessage(content=\"Great choice! Would you like to add any side items, such as garlic bread, choco lava cake, or chicken taco?\"),\n",
    "        HumanMessage(content=\"Yes, add a garlic bread. Also, is a medium pizza enough for 3 people?\"),\n",
    "        AIMessage(content=\"A medium pizza is generally enough for about 2 people. Would you like to consider ordering a large pizza instead?\"),\n",
    "        HumanMessage(content=\"Yes\"),\n",
    "        AIMessage(content=\"I've updated your order to a large pizza with onion, capsicum, and tomato toppings, along with a garlic bread. Would you like to add any additional toppings or side items?\"),\n",
    "        HumanMessage(content=\"No. That's all.\"),\n",
    "        AIMessage(content=\"Thank you for your order! Just to confirm, you've ordered a large pizza with onion, capsicum, and tomato toppings, along with a garlic bread. Is this correct? If so, I'll place your order.\"),\n",
    "        HumanMessage(content=\"Yes, that's correct.\")\n",
    "\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edeec6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'pending'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_status_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea16dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_taker'}}\n",
      "----\n",
      "{'order_taker': {'messages': [HumanMessage(content=\"Certainly! I've confirmed your order for a medium pizza with onion, capsicum, and tomato toppings, and no sides. Your order has been placed successfully. Is there anything else you'd like to know about your order?\", name='order_taker', id='3041942a-504c-4b0d-b24d-0432f9c2f9c1')], 'size': 'medium', 'toppings': ['onions', 'capsicum', 'tomatoes'], 'sides': [], 'confirmed': True}}\n",
      "----\n",
      "{'order_place': {'messages': [AIMessage(content='Your order has been placed successfully! Your order id is:\\n2', name='order_place')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to order a medium pizza with onion, capsicum and tomato toppings and no sides. Please consider the order confirmed\"),        \n",
    "\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58fa7b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'pending', 2: 'pending'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_status_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f0c9dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_status'}}\n",
      "----\n",
      "{'order_status': {'messages': [HumanMessage(content=\"Certainly! I'd be happy to help you check the status of your order. However, to retrieve the status, I'll need the order ID. The order ID is typically a number assigned to your order when you placed it.\\n\\nCould you please provide me with your order ID? Once I have that information, I can use our system to check the status for you.\", name='order_status', id='c74d1622-eff7-49c7-b0af-914642b38215')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to know the status of my order\"),\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58663834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'pending', 2: 'pending'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_status_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35b8e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_status'}}\n",
      "----\n",
      "{'order_status': {'messages': [HumanMessage(content=\"Based on the information I've received, I can inform you that Order 1 is currently pending. This means that your order has been received and is being processed, but it hasn't been completed or shipped yet.\\n\\nIs there anything else you'd like to know about your order or any other assistance I can provide?\", name='order_status', id='2eaa4741-7b00-4589-a92b-478391f45cc2')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to know the status of my order\"),\n",
    "        AIMessage(content=\"Certainly! I'd be happy to help you check the status of your order. However, to retrieve the status, I'll need the order ID. The order ID is typically a number assigned to your order when you placed it.\\n\\nCould you please provide me with your order ID? Once I have that information, I can use our system to check the status for you.\"),\n",
    "        HumanMessage(content=\"My order id is 1\")\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64527417",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_status_db[1]=\"Dispatched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b4522a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_status'}}\n",
      "----\n",
      "{'order_status': {'messages': [HumanMessage(content=\"Great news! I've retrieved the status of your order. The system shows that Order 1 is Dispatched. \\n\\nThis means that your order has been prepared and is now on its way to you. It has left our facility and is in the delivery process. You should receive it soon, depending on your location and the delivery method chosen.\\n\\nIs there anything else you'd like to know about your order or any other assistance I can provide?\", name='order_status', id='45ec9c64-e3f4-4f41-a066-733280d80f67')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to know the status of my order\"),\n",
    "        AIMessage(content=\"Certainly! I'd be happy to help you check the status of your order. However, to retrieve the status, I'll need the order ID. The order ID is typically a number assigned to your order when you placed it.\\n\\nCould you please provide me with your order ID? Once I have that information, I can use our system to check the status for you.\"),\n",
    "        HumanMessage(content=\"My order id is 1\")\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9d61000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'order_taker'}}\n",
      "----\n",
      "{'order_taker': {'messages': [HumanMessage(content=\"Certainly! I'd be happy to help you order a pizza with onion, capsicum, and tomato toppings. That sounds delicious! I've noted down your toppings. Could you please tell me what size pizza you'd like? We have small, medium, and large options available.\", name='order_taker', id='ce13076f-7ff5-4e7d-8474-512e4e4fe6a8')], 'size': 'medium', 'toppings': ['onions', 'capsicum', 'tomatoes'], 'sides': [], 'confirmed': False}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        HumanMessage(content=\"I want to order a pizza with onion, capsicum and tomato toppings.\"),        \n",
    "\n",
    "]\n",
    "events = graph.stream({\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b9b37649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "class CustomFormatter(logging.Formatter):\n",
    "\n",
    "    grey = \"\\x1b[38;20m\"\n",
    "    yellow = \"\\x1b[33;20m\"\n",
    "    red = \"\\x1b[31;20m\"\n",
    "    bold_red = \"\\x1b[31;1m\"\n",
    "    reset = \"\\x1b[0m\"\n",
    "    format = \"%(message)s\"\n",
    "\n",
    "    FORMATS = {\n",
    "        logging.DEBUG: grey + format + reset,\n",
    "        logging.INFO: red + format + reset,\n",
    "        logging.WARNING: yellow + format + reset,\n",
    "        logging.ERROR: red + format + reset,\n",
    "        logging.CRITICAL: bold_red + format + reset\n",
    "    }\n",
    "\n",
    "    def format(self, record):\n",
    "        log_fmt = self.FORMATS.get(record.levelno)\n",
    "        formatter = logging.Formatter(log_fmt)\n",
    "        return formatter.format(record)\n",
    "logger = logging.getLogger(\"PizzaOrderBot\")\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "ch.setFormatter(CustomFormatter())\n",
    "\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1d222af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive():\n",
    "    message=input(\"Welcome to the Robo Pizza Hut. How can I help you today?\")\n",
    "    print(\"Welcome to the Robo Pizza Hut. How can I help you today?\")\n",
    "    messages = [\n",
    "            HumanMessage(content=message),        \n",
    "        ]\n",
    "    while(True):        \n",
    "        if message in [\"exit\",\"q\",\"quit\"]:\n",
    "            break\n",
    "        messages.append(HumanMessage(content=message))\n",
    "        print(message)\n",
    "        events = graph.stream({\n",
    "                \"messages\": messages,\n",
    "            },\n",
    "            # Maximum number of steps to take in the graph\n",
    "            {\"recursion_limit\": 5},\n",
    "        )\n",
    "        events=list(events)\n",
    "        for s in events:\n",
    "            \n",
    "            logger.info(s)\n",
    "            # print(\"----\")\n",
    "        if len(events)>0:            \n",
    "            last_event=events[-1]\n",
    "            v=list(last_event.values())[-1]\n",
    "            if \"messages\" in v:\n",
    "                m=v[\"messages\"][-1]\n",
    "                messages.append(AIMessage(m.content)) \n",
    "                print(m.content)            \n",
    "            message=input()\n",
    "        else:\n",
    "            print(\"No event recieved\")\n",
    "            print(events)\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ac53b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Robo Pizza Hut. How can I help you today?\n",
      "Hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m{'supervisor': {'next': 'helper'}}\u001b[0m\n",
      "INFO:PizzaOrderBot:{'supervisor': {'next': 'helper'}}\n",
      "\u001b[38;20m{'helper': {'messages': [AIMessage(content='Hi there! How can I assist you with your pizza order today?', name='helper', id='ec243f08-081f-4c3f-b0ac-86017709d710')]}}\u001b[0m\n",
      "INFO:PizzaOrderBot:{'helper': {'messages': [AIMessage(content='Hi there! How can I assist you with your pizza order today?', name='helper', id='ec243f08-081f-4c3f-b0ac-86017709d710')]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I assist you with your pizza order today?\n"
     ]
    }
   ],
   "source": [
    "interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9e084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
